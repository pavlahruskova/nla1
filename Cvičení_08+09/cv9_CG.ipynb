{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cvičení 9\n",
    "\n",
    "Jedna z nejefektivnějších metod pro iterační řešení soustav lineárních rovnic se se symetrickou pozitivně definitní maticí je metoda sdružených gradientů (anglicky Conjugate Gradient Method, CG).\n",
    "\n",
    "## Metoda sdružených gradientů\n",
    "\n",
    "CG je gradientní iterační metoda, která vytváří posloupnost A-ortogonálních (sdružených) vektorů. Nový vektor je z předchozích určen pomocí postupu založeného na Gramově-Schmidtově ortogonalizaci. Využijte pseudokód z přednášky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Příklad 1\n",
    "\n",
    "Doplňte správné řešení Metody sdružených gradientů do buňky níže dle algoritmu z přednášek: \n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\text{Input: SPD matrix } A, \\text{ right-hand side vector } b, \\text{ initial approximation } x_0, \\epsilon \\in (0,1), \\text{ maximum number of iterations max\\_it.}\\\\\n",
    "\\ \\\\\n",
    "k = 0  \\\\\n",
    "\\ \\\\\n",
    "d^0 := r^0 := b - Ax^0 \\\\\n",
    "\\ \\\\\n",
    "\\text{\\bf{while} } ||r^k|| /||r^0|| > \\epsilon \\\\\n",
    "\\ \\\\    \n",
    "\\quad\\begin{array}{l}\n",
    "    %\\alpha_k := (r^k)^T d^k / (d^k)^T A d^k \\\\\n",
    "    \\alpha_k := \\frac{(r^k)^T d^k} {(d^k)^T A d^k} \\\\\n",
    "    \\ \\\\    \n",
    "    x^{k+1} := x^k + \\alpha_k d^k \\\\ \n",
    "    \\ \\\\    \n",
    "    r^{k+1} := r^k - \\alpha_k Ad^k \\\\ \n",
    "    \\ \\\\     \n",
    "    %\\beta_k := (r^k)^T d^k / (d^k)^T A d^k \\\\\n",
    "    \\beta_k := \\frac{(r^{k+1})^T A d^k} {(d^k)^T A d^k} \\\\\n",
    "    \\ \\\\    \n",
    "    d^{k+1} := r^{k+1} - \\beta_k d^k \\\\\n",
    "    \\ \\\\\n",
    "    k = k + 1 \\\\\n",
    "\\end{array}\\\\\n",
    "\\ \\\\\n",
    "\\text{end while}\\\\\n",
    "\\ \\\\\n",
    "\\text{The solution is stored in } x^{k}.\\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÚKOL: Doplňte chybějící kód ve while cyklu metody sdružených gradientů\n",
    "\n",
    "def conjugate_gradients(A, b, x0, epsilon=1e-8, max_it=1000):\n",
    "    \"\"\"\n",
    "    Resi system Ax=b s SPD matici A pomoci metody sdruzenych gradientu.\n",
    "    A: matice soustavy\n",
    "    b: vektor prave strany\n",
    "    x0: pocatecni odhad\n",
    "    epsilon: relativni presnost\n",
    "    max_it: maximalni pocet iteraci\n",
    "    \"\"\"\n",
    "    # citac iteraci\n",
    "    k = 0\n",
    "\n",
    "    # vektor pocatecniho rezidua a pocatecniho smeru\n",
    "    x = x0 # x0.copy()\n",
    "    d = r = b - A @ x\n",
    "    # d = r.copy()\n",
    " \n",
    "    # vytvorime pole, do ktereho budeme ukladat normy rezidua v jednotlivych iteracich\n",
    "    residuals = [np.linalg.norm(r)]\n",
    " \n",
    "    # pro vypocet ukoncovaci podminky   \n",
    "    r0_norm = np.linalg.norm(b - A @ x0)    \n",
    "       \n",
    "    while k < max_it and ((np.linalg.norm(r) / r0_norm) > epsilon):\n",
    "        # pomocny vypocet (usetrime 4 operace nasobeni matice-vektor):\n",
    "        Ad = A @ d\n",
    "        \n",
    "        #  vypoctete alpha_k, x_{k+1} and r_{k+1}:\n",
    "        alpha = \n",
    "        x = \n",
    "        r_new = \n",
    "        \n",
    "        # vypoctete beta_k, d_{k+1}:\n",
    "        beta = \n",
    "        d = \n",
    "        r = r_new\n",
    "        \n",
    "        # navysime citac iteraci\n",
    "        k += 1        \n",
    "    \n",
    "        # ulozime reziduum\n",
    "        residuals.append(np.linalg.norm(r))\n",
    "\n",
    "    return x, k, residuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otestujeme vasi metodu\n",
    "\n",
    "n = 100\n",
    "U = np.triu(np.random.rand(n, n), 1)\n",
    "d = 100 * np.random.rand(n, 1)\n",
    "A = np.diag(d.flatten()) + U + U.T  # matice soustavy\n",
    "b = np.random.rand(n, 1)            # vektor prave strany\n",
    "x0 = np.zeros((n, 1))               # pocatecni odhad reseni\n",
    "\n",
    "x, k, _ = conjugate_gradients(A, b, x0, 1e-8, 100)\n",
    "x_np = np.linalg.solve(A, b)\n",
    "print(\"Pocet iteraci: {}\".format(k))\n",
    "print(\"||x - x_np|| = {}\".format(np.linalg.norm(x - x_np)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UKOL: upravte metodu tak, aby vracela vektor residuals, na jehoz konec v kazde \n",
    "# iteraci ulozite aktualni normu rezidua.\n",
    "# Pote pomoci knihovny matplotlib vykreslete graf normy rezidua v zavislosti na iteraci.\n",
    "#\n",
    "# Graf by mel obsahovat: Nadpis (title), popisky os, mrizku (grid)\n",
    "#\n",
    "# Pro lepsi prehlednost se pokuste graf vykreslit take s logaritmickou skalou na ose y.\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
